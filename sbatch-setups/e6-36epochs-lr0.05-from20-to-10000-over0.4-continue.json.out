TestTrain
Settings from ./sbatch-setups/e6-36epochs-lr0.05-from20-to-10000-over0.4-continue.json
[rank: 0] Global seed set to 4222
/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/lightning_fabric/connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Global seed set to 4222
initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1
/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /pfs/work7/workspace/scratch/ma_dsperber-industry/models exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
loading torch...imported torchimported lightning and albumentations. Importing model framework...
Frameworks
Namespace(settings='./sbatch-setups/e6-36epochs-lr0.05-from20-to-10000-over0.4-continue.json', ckpt_path=None, no_log=True)
Using customized paths: {'bboxes': '/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/data/', 'images': '/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/data/'}
{'dataset': {'accumulate_batch_size': 1,
             'batch_size': 6,
             'eval_batch_scale': 10,
             'image_size': [1280, 1280],
             'name': 'CropsOrWeed9',
             'num_workers': 8,
             'seed': 4222,
             'stack2_images': True,
             'use_extra_class': 0},
 'loss': {'box_loss_weight': 0.05,
          'cls_loss_weight': 0.5,
          'obj_loss_weight': 1.0,
          'ota_loss': True},
 'lr_onecycle': {'base_momentum': 0.8,
                 'div_factor': 20.0,
                 'final_div_factor': 10000.0,
                 'max_momentum': 0.937,
                 'pct_start': 0.4},
 'lr_scheduler': {'milestone_multiplier': 0.1,
                  'milestones': [40, 50],
                  'warmup_epochs': 1,
                  'warmup_multiplier': 0.2},
 'mAP': {'iou_threshold': 0.7,
         'max_detections': 150,
         'min_confidence': 0.02,
         'nms_threshold': 0.02},
 'model': {'freeze': False,
           'name': 'yolov7-e6',
           'pretrained': True,
           'weight_path': False},
 'optimizer': {'learning_rate': 0.05,
               'lr_scheduler': 'OneCycleLR',
               'name': 'SGD',
               'weight_decay': 0.0005},
 'trainer': {'accumulate_grad_batches': 2,
             'check_val_every_n_epoch': 2,
             'ckpt_path': 'CropAndWeedDetection/models/CropsOrWeed9_1280px_yolov7-e6_epoch=9_lr=_batch=8_val_loss=3.971_map=0.167-last.ckpt',
             'deepspeed_config': {'train_batch_size': 12,
                                  'train_micro_batch_size_per_gpu': 6,
                                  'zero_allow_untested_optimizer': True,
                                  'zero_force_ds_cpu_optimizer': False,
                                  'zero_optimization': {'allgather_bucket_size': 500000000.0,
                                                        'offload_optimizer': {'device': 'cpu',
                                                                              'pin_memory': True},
                                                        'reduce_bucket_size': 500000000.0,
                                                        'stage': 2}},
             'disable_val_sanity_checks': True,
             'max_epochs': 36,
             'precision': 16,
             'strategy': 'auto',
             'val_check_interval': False}}
Using Deepseed True batch size 6



...Data Module initialized
Transferred 874/896 items from https://github.com/Chris-hughes10/Yolov7-training/releases/download/0.1.0/yolov7-e6_training_state_dict.pt
Model created

Data paths already exists. Skipping download and mask generation. No integrity check was performed.
BBoxes cached in 6e+01 s
BBoxes cached in 8e+00 s
model type torch.float32
Using OneCycleLR scheduler
[2023-04-10 00:11:44,128] [WARNING] [engine.py:1214:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Using /pfs/data5/home/ma/ma_ma/ma_dsperber/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Emitting ninja build file /pfs/data5/home/ma/ma_ma/ma_dsperber/.cache/torch_extensions/py39_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/torch/include -isystem /pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/torch/include/TH -isystem /pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/torch/include/THC -isystem /usr/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o 
[2/2] c++ flatten_unflatten.o -shared -L/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so
Loading extension module utils...
Using /pfs/data5/home/ma/ma_ma/ma_dsperber/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...

  | Name     | Type                 | Params
--------------------------------------------------
0 | model    | Yolov7Model          | 110 M 
1 | mAP      | MeanAveragePrecision | 0     
2 | test_mAP | MeanAveragePrecision | 0     
--------------------------------------------------
110 M     Trainable params
0         Non-trainable params
110 M     Total params
442.130   Total estimated model params size (MB)
Restoring states from the checkpoint path at CropAndWeedDetection/models/CropsOrWeed9_1280px_yolov7-e6_epoch=9_lr=_batch=8_val_loss=3.971_map=0.167-last.ckpt
Time to load utils op: 61.84372091293335 seconds
Rank: 0 partition count [1, 1] and sizes[(97528, False), (110435008, False)] 
Time to load utils op: 0.0009372234344482422 seconds
Fitting yolov7-e6 on CropsOrWeed9 with SGD

[2023-04-10 00:12:49,880] [WARNING] [engine.py:2769:load_checkpoint] Unable to find latest file at CropAndWeedDetection/models/CropsOrWeed9_1280px_yolov7-e6_epoch=9_lr=_batch=8_val_loss=3.971_map=0.167-last.ckpt/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Traceback (most recent call last):
  File "/pfs/data5/home/ma/ma_ma/ma_dsperber/CropAndWeedDetection/train.py", line 370, in <module>
    train()
  File "/pfs/data5/home/ma/ma_ma/ma_dsperber/CropAndWeedDetection/train.py", line 357, in train
    pprint(trainer.fit(pl_model, data, ckpt_path=settings['trainer']['ckpt_path']))
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 520, in fit
    call._call_and_handle_interrupt(
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 92, in launch
    return function(*args, **kwargs)
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 559, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 922, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 395, in _restore_modules_and_callbacks
    self.resume_start(checkpoint_path)
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 82, in resume_start
    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)
  File "/pfs/work7/workspace/scratch/ma_dsperber-industry/cropandweed-dataset/workenv/lib64/python3.9/site-packages/pytorch_lightning/strategies/deepspeed.py", line 791, in load_checkpoint
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: DeepSpeed was unable to load the checkpoint. Ensure you passed in a DeepSpeed compatible checkpoint or a single checkpoint file with `Trainer(strategy=DeepSpeedStrategy(load_full_weights=True))`.

============================= JOB FEEDBACK =============================

NodeName=uc2n511
Job ID: 21995006
Cluster: uc2
User/Group: ma_dsperber/ma_ma
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 10
CPU Utilized: 00:00:30
CPU Efficiency: 0.96% of 00:52:10 core-walltime
Job Wall-clock time: 00:05:13
Memory Utilized: 3.21 GB
Memory Efficiency: 5.01% of 64.00 GB
